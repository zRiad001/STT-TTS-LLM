#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Riad Project â€” AddÄ±m 11
VAD É™saslÄ± sÉ™s yazÄ±cÄ± + Vosk transkripsiya Ã§aÄŸÄ±rÄ±ÅŸÄ±

Qeyd: Terminal emoji-lÉ™ri encoding xÉ™tasÄ± verÉ™rsÉ™, UTFâ€‘8 rejimini aktiv edin:
- BirdÉ™fÉ™lik: `PYTHONUTF8=1 python3 vad_rec_transcribe.py`
- vÉ™ ya sabit: `export PYTHONUTF8=1`
- Avtomatik input device seÃ§imi (istÉ™sÉ™n É™l ilÉ™ dÉ™ yaza bilÉ™rsÉ™n)
- Preroll/postroll, histerezis, NOISE_GATE
- SRT/TXT Ã¼Ã§Ã¼n transcribe_vosk.py Ã§aÄŸÄ±rÄ±ÅŸÄ± (CALL_TRANSCRIBE=True olduqda)
"""

import os, sys, time, wave, struct, collections
import webrtcvad
import sounddevice as sd

# --- Output encoding guard (emoji/special chars safe) ---
try:
    sys.stdout.reconfigure(encoding='utf-8', errors='ignore')
    sys.stderr.reconfigure(encoding='utf-8', errors='ignore')
except Exception:
    pass

# ====================== USER SETTINGS ======================
# Cihaz seÃ§imi: None â†’ avtomatik input kanallÄ± ilk cihazÄ± tapÄ±r.
# Konkret indeks bilirsÉ™nsÉ™, mÉ™sÉ™lÉ™n MIC ADC (hw:0,1) Ã¼Ã§Ã¼n 1 yaz.
DEVICE_INDEX   = 12      # pulse (bizdÉ™ iÅŸlÉ™yir)
SAMPLE_RATE    = 48000   # Pulse Ã¼Ã§Ã¼n real native rate
CHANNELS       = 1       # Pulse-da mono istifadÉ™ et
NOISE_GATE     = 300
START_TRIGGER_FRAMES = 8
STOP_TRIGGER_FRAMES  = 40
FRAME_MS       = 20       # frame uzunluÄŸu (ms)
DTYPE          = 'int16'
VAD_LEVEL      = 2        # daha sÉ™rt (0..3)

NOISE_GATE           = 500  # |amplituda| hÉ™ddi (400â€“900 aralÄ±ÄŸÄ±nda oynat)
MIN_HOLD_AFTER_START_MS   = 900  # startdan sonra bu qÉ™dÉ™r mÃ¼ddÉ™t stop etmÉ™
MIN_SPEECH_MS             = 1200 # faydalÄ± danÄ±ÅŸÄ±q minimumu (ms)
# Kontekst:
PREROLL_FRAMES = 15   # ~300 ms
POSTROLL_FRAMES = 10  # ~200 ms
# DavranÄ±ÅŸ:
EXIT_AFTER_FIRST_STOP = True
MAX_DURATION_S = 180
OUT_WAV        = "output.wav"
CALL_TRANSCRIBE= True
# ====================== USER SETTINGS ======================

FRAME_SAMPLES = int(SAMPLE_RATE * FRAME_MS / 1000)  # frame baÅŸÄ±na N nÃ¼munÉ™ (kanal baÅŸÄ±na)
FRAME_BYTES   = FRAME_SAMPLES * 2 * CHANNELS         # hÉ™r nÃ¼munÉ™ int16, CHANNELS-É™ vurulur


def write_wav(path, sample_rate, pcm16_bytes):
    with wave.open(path, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(pcm16_bytes)


def rms16(samples):
    # sadÉ™ RMS (float istifadÉ™ etmirik ki, sÃ¼rÉ™tli olsun)
    s2 = 0
    for s in samples:
        s2 += s*s
    # qeyri-xÉ™tti kÃ¶k â€” kifayÉ™t qÉ™dÉ™r dÉ™qiqdir burada
    return (s2 // max(1, len(samples))) ** 0.5


def pick_input_device(prefer_index=None):
    """Input kanallÄ± cihaz seÃ§imi. prefer_index verilmiÅŸsÉ™, onu qaytarÄ±r."""
    try:
        if prefer_index is not None:
            return prefer_index
        devs = sd.query_devices()
        # max_input_channels > 0 olan ilk cihazÄ± gÃ¶tÃ¼r
        for i, d in enumerate(devs):
            if d.get('max_input_channels', 0) > 0:
                return i
    except Exception:
        pass
    return 0  # fallback


def main():
    global DEVICE_INDEX

    # CihazÄ± seÃ§
    DEVICE_INDEX = pick_input_device(DEVICE_INDEX)

    # sounddevice default-lar
    sd.default.device     = DEVICE_INDEX
    sd.default.samplerate = SAMPLE_RATE
    sd.default.channels   = CHANNELS
    sd.default.dtype      = DTYPE

    print(f"\U0001F399\ufe0f VAD recorder @ {SAMPLE_RATE} Hz, {FRAME_MS} ms frames â†’ {FRAME_BYTES} bytes")
    print(f"\U0001F527 Using input device index: {DEVICE_INDEX}")

    vad  = webrtcvad.Vad(VAD_LEVEL)
    ring = collections.deque(maxlen=STOP_TRIGGER_FRAMES)

    in_speech       = False
    recording       = False
    bytes_buf       = bytearray()
    preroll         = collections.deque(maxlen=PREROLL_FRAMES)
    tail_postroll   = collections.deque(maxlen=POSTROLL_FRAMES)
    all_audio       = bytearray()
    overall_start   = time.time()
    start_time      = 0.0
    hold_until_time = 0.0

    # Kalibrasiya Ã¼Ã§Ã¼n sadÉ™ pik logu (startdan É™vvÉ™l hÉ™r ~0.5 s)
    last_pk_log = [0.0]

    def push_to_output(frame_bytes):
        nonlocal all_audio
        all_audio.extend(frame_bytes)

    def handle_frame(frame_bytes):
        nonlocal in_speech, recording, start_time, hold_until_time
        # frame Ã¶lÃ§Ã¼sÃ¼ dÉ™qiq olsun (multiâ€‘channel nÉ™zÉ™rÉ™ alÄ±nÄ±b)
        if len(frame_bytes) != FRAME_BYTES:
            bytes_buf.extend(frame_bytes)
            while len(bytes_buf) >= FRAME_BYTES:
                chunk = bytes(bytes_buf[:FRAME_BYTES])
                del bytes_buf[:FRAME_BYTES]
                handle_frame(chunk)
            return

        # --- Downmix to mono (É™gÉ™r CHANNELS>1) ---
        total_samples = len(frame_bytes) // 2
        samples_all = struct.unpack('<%dh' % total_samples, frame_bytes)
        if CHANNELS > 1:
            # 2 kanal varsayÄ±rÄ±q; daha Ã§ox olarsa, ortalama/max ala bilÉ™rsÉ™n
            mono = []
            for i in range(0, total_samples, CHANNELS):
                # sadÉ™ ortalama: L,R â†’ mono
                acc = 0
                cnt = 0
                for c in range(CHANNELS):
                    if i + c < total_samples:
                        acc += samples_all[i + c]
                        cnt += 1
                mono.append(int(acc / max(1, cnt)))
            mono_bytes = struct.pack('<%dh' % len(mono), *mono)
            samples = mono
        else:
            mono_bytes = frame_bytes
            samples = samples_all

        # NOISE-GATE + VAD mono Ã¼zrÉ™
        pk = max(abs(s) for s in samples) if samples else 0
        gate_silence = (pk < NOISE_GATE)
        voiced = (not gate_silence) and vad.is_speech(mono_bytes, SAMPLE_RATE)
        ring.append(1 if voiced else 0)

        # startdan É™vvÉ™l pk-lÉ™ri gÃ¶stÉ™r (kalibrasiya Ã¼Ã§Ã¼n)
        now = time.time()
        if not in_speech and now - last_pk_log[0] > 0.5:
            print(f"   â†ªï¸ pk={pk}")
            last_pk_log[0] = now

        # preroll-u hÉ™miÅŸÉ™ saxla (yazÄ±ya baÅŸlamamÄ±ÅŸdan É™vvÉ™lki ~300ms)
        preroll.append(mono_bytes)

        # START
        if not in_speech:
            if sum(ring) >= START_TRIGGER_FRAMES:
                in_speech = True
                recording = True
                start_time = now
                hold_until_time = now + (MIN_HOLD_AFTER_START_MS / 1000.0)
                print("â–¶ï¸ BaÅŸladÄ± (speech detected)")
                # preroll-u Ã§Ä±xÄ±ÅŸa dump et ki, ilk hecalar kÉ™silmÉ™sin
                while preroll:
                    push_to_output(preroll.popleft())
                # cari frame-i dÉ™ yaz
                push_to_output(mono_bytes)
                return
            else:
                # hÉ™lÉ™ baÅŸlamamÄ±ÅŸÄ±q â€” Ã§Ä±xÄ±ÅŸa yazmÄ±rÄ±q
                return

        # DanÄ±ÅŸÄ±qda: yazmaÄŸa davam et
        if recording:
            push_to_output(mono_bytes)
            tail_postroll.append(mono_bytes)

        # STOP
        if in_speech:
            if now < hold_until_time:
                return  # startdan dÉ™rhal sonra stop etmÉ™
            # â€œflapâ€Ä± azaltmaq Ã¼Ã§Ã¼n Ã§ox az aktivlik dÉ™ stop sayÄ±lÄ±r
            if sum(ring) <= 2 and len(ring) >= STOP_TRIGGER_FRAMES:
                in_speech = False
                print("â¹ï¸ DayandÄ±rÄ±ldÄ± (silence)")
                # postroll (qÄ±sa quyruq) É™lavÉ™ et
                while tail_postroll:
                    push_to_output(tail_postroll.popleft())
                if EXIT_AFTER_FIRST_STOP:
                    return "STOP"

        # NOISE-GATE + VAD
        samples = struct.unpack("<%dh" % (len(frame_bytes)//2), frame_bytes)
        pk = max(abs(s) for s in samples)
        gate_silence = (pk < NOISE_GATE)
        voiced = (not gate_silence) and vad.is_speech(frame_bytes, SAMPLE_RATE)
        ring.append(1 if voiced else 0)

        # startdan É™vvÉ™l pk-lÉ™ri gÃ¶stÉ™r (kalibrasiya Ã¼Ã§Ã¼n)
        now = time.time()
        if not in_speech and now - last_pk_log[0] > 0.5:
            print(f"   â†ªï¸ pk={pk}")
            last_pk_log[0] = now

        # preroll-u hÉ™miÅŸÉ™ saxla (yazÄ±ya baÅŸlamamÄ±ÅŸdan É™vvÉ™lki ~300ms)
        preroll.append(frame_bytes)

        # START
        if not in_speech:
            if sum(ring) >= START_TRIGGER_FRAMES:
                in_speech = True
                recording = True
                start_time = now
                hold_until_time = now + (MIN_HOLD_AFTER_START_MS / 1000.0)
                print("â–¶ï¸ BaÅŸladÄ± (speech detected)")
                # preroll-u Ã§Ä±xÄ±ÅŸa dump et ki, ilk hecalar kÉ™silmÉ™sin
                while preroll:
                    push_to_output(preroll.popleft())
                # cari frame-i dÉ™ yaz
                push_to_output(frame_bytes)
                return
            else:
                # hÉ™lÉ™ baÅŸlamamÄ±ÅŸÄ±q â€” Ã§Ä±xÄ±ÅŸa yazmÄ±rÄ±q
                return

        # DanÄ±ÅŸÄ±qda: yazmaÄŸa davam et
        if recording:
            push_to_output(frame_bytes)
            tail_postroll.append(frame_bytes)

        # STOP
        if in_speech:
            if now < hold_until_time:
                return  # startdan dÉ™rhal sonra stop etmÉ™
            # â€œflapâ€Ä± azaltmaq Ã¼Ã§Ã¼n Ã§ox az aktivlik dÉ™ stop sayÄ±lÄ±r
            if sum(ring) <= 2 and len(ring) >= STOP_TRIGGER_FRAMES:
                in_speech = False
                print("â¹ï¸ DayandÄ±rÄ±ldÄ± (silence)")
                # postroll (qÄ±sa quyruq) É™lavÉ™ et
                while tail_postroll:
                    push_to_output(tail_postroll.popleft())
                if EXIT_AFTER_FIRST_STOP:
                    return "STOP"

    try:
        with sd.RawInputStream(
            device=DEVICE_INDEX,
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=DTYPE,
            blocksize=FRAME_SAMPLES,
        ) as stream:
            print("\ud83d\udce2 DanÄ±ÅŸ â€” sÃ¼kutda avtomatik dayanacaq. (Ctrl+C ilÉ™ dÉ™ dayandÄ±rmaq olar)")
            while True:
                data, _ = stream.read(FRAME_SAMPLES)
                if not data:
                    continue
                res = handle_frame(bytes(data))
                if res == "STOP" and EXIT_AFTER_FIRST_STOP:
                    break
                if time.time() - overall_start > MAX_DURATION_S:
                    print("â³ Vaxt limiti Ã§atdÄ± â€” dayandÄ±rÄ±lÄ±r.")
                    break
    except KeyboardInterrupt:
        print("\nğŸ›‘ Klaviaturadan dayandÄ±rÄ±ldÄ±.")
    except Exception as e:
        print("âŒ Stream aÃ§Ä±lmadÄ±:", e)
        sys.exit(1)

    # Ã§ox qÄ±sa danÄ±ÅŸÄ±q olmasÄ±n
    speech_ms = (len(all_audio) / FRAME_BYTES) * FRAME_MS
    if speech_ms < MIN_SPEECH_MS:
        print(f"âš ï¸ Ã‡ox qÄ±sa audio ({int(speech_ms)} ms). HÉ™dlÉ™ri yumÅŸalt vÉ™ ya bir az daha uzun danÄ±ÅŸ.")
        # YenÉ™ dÉ™ yazÄ±rÄ±q ki, yoxlaya bilÉ™sÉ™n
    write_wav(OUT_WAV, SAMPLE_RATE, bytes(all_audio))
    print(f"ğŸ’¾ Yadda saxlanÄ±ldÄ±: {OUT_WAV}  (~{int(speech_ms)} ms)")

    if CALL_TRANSCRIBE and os.path.exists("transcribe_vosk.py"):
        print("ğŸ“ Transkripsiya baÅŸlayÄ±r (vosk)...")
        rc = os.system(f"python3 transcribe_vosk.py {OUT_WAV} --model ./model --no-grammar")
        if rc != 0:
            print("âš ï¸ transcribe_vosk.py uÄŸursuz Ã§Ä±xdÄ±.")
    else:
        if CALL_TRANSCRIBE:
            print("â„¹ï¸ transcribe_vosk.py tapÄ±lmadÄ± â€” yalnÄ±z WAV saxlandÄ±.")


if __name__ == "__main__":
    try:
        import webrtcvad  # noqa: F401
    except ImportError:
        print("âš ï¸ webrtcvad paketini quraÅŸdÄ±r:  pip install webrtcvad")
        sys.exit(1)
    main()
