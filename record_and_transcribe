from pathlib import Path
from vad_record import record_vad
from faster_whisper import WhisperModel


import requests
from gtts import gTTS
import os

def speak(text: str, lang="en"):
    """Natural-sounding voice using gTTS (Google TTS)"""
    try:
        tts = gTTS(text=text, lang=lang)
        tts.save("/tmp/tts.mp3")
        os.system("mpg123 /tmp/tts.mp3 > /dev/null 2>&1")
    except Exception as e:
        print("TTS error:", e)






def record_and_transcribe():
    out = Path.home() / "Desktop" / "output.wav"

    # S∆èS YAZ (s…ônin m√∂vcud funksiyanƒ±n imzasƒ±na uyƒüundur)
    file_path = record_vad(
        output=str(out),
        silence_limit=1.2,   # ist…ôyin…ô g√∂r…ô d…ôyi≈ü…ô bil…ôrs…ôn
        device=None          # lazƒ±m olsa indeks ver
    )
    if not file_path or not Path(file_path).exists():
        print("‚ùå S…ôs yazƒ±la bilm…ôdi.")
        return

    print(f"üéß Yazƒ±lmƒ±≈ü fayl: {file_path}")

    # WHISPER STT
    print("üß† Whisper transkripsiya ba≈ülayƒ±r...")
    model = WhisperModel("base", device="cpu", compute_type="int8")  # "tiny" daha s√ºr…ôtli
    segments, info = model.transcribe(str(out), vad_filter=True, beam_size=1, best_of=1)
    print(f"üåê Dil: {info.language}")

    text = "".join(s.text for s in segments).strip()
    print("\nüìù N…ôtic…ô:")
    print(text or "[bo≈ü]")
# After printing STT text:
    if text:
        reply = ollama_chat(text)
        print("\nü§ñ Reply:\n" + reply)
        piper_tts(reply)
# --- ADD: LLM + TTS ---
import os, json, tempfile, subprocess, requests
import simpleaudio as sa
from pathlib import Path

OLLAMA_HOST = os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
LLM_MODEL   = os.environ.get("LLM_MODEL", "qwen2.5:7b-instruct")
PIPER_BIN   = os.environ.get("PIPER_BIN", str(Path.home() / "Desktop/piper/piper"))
PIPER_MODEL = os.environ.get("PIPER_MODEL", str(Path.home() / "Desktop/piper_voices/en_US-amy-medium.onnx"))





# replace your ollama_chat() with this generate-only version
import requests

OLLAMA_URL = "http://127.0.0.1:11434/v1/chat/completions"
MODEL_NAME = "mistral"  # S…ônd…ô hansƒ± modeldirs…ô onu yaz (m…ôs: "llama3", "phi3", n…ôdirs…ô)

import requests









import requests

def ollama_chat(user_text: str) -> str:
    """Send prompt to Ollama LLM and read answer aloud"""
    url = "http://127.0.0.1:11434/v1/chat/completions"
    payload = {
        "model": "mistral:latest",
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are a helpful AI assistant. "
                    "Always respond only in English. "
                    "Do not translate or repeat in other languages. "
                    "If the user speaks another language, still answer strictly in English. "
                    "Never include translations or bilingual text."
                )
            },
            {
                "role": "user",
                "content": user_text
            }
        ],
        "stream": False
    }

    try:
        resp = requests.post(url, json=payload)
        resp.raise_for_status()
        data = resp.json()
        answer = data["choices"][0]["message"]["content"].strip()
        print("ü§ñ Reply:", answer)
        speak(answer)  # üîä s…ôsli oxut
        return answer
    except Exception as e:
        print("‚ùå LLM request failed:", e)
        return "Error: LLM request failed."








def piper_tts(text: str):
    if not Path(PIPER_MODEL).exists():
        raise RuntimeError(f"Piper model not found: {PIPER_MODEL}")
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tf:
        outwav = tf.name
    cmd = [PIPER_BIN, "--model", PIPER_MODEL, "--output_file", outwav,
           "--length_scale","1.0","--noise_scale","0.33","--noise_w","0.5"]
    p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    _, err = p.communicate(input=text.encode("utf-8"))
    if p.returncode != 0:
        raise RuntimeError(f"Piper failed: {err.decode(errors='ignore')}")
    wav = sa.WaveObject.from_wave_file(outwav)
    play = wav.play(); play.wait_done()
    try: os.unlink(outwav)
    except: pass
# --- END ADD ---


if __name__ == "__main__":
    record_and_transcribe()
