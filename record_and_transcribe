# record_and_transcribe.py  (CPU-only, clean)
from pathlib import Path
import argparse
import os
import tempfile
import subprocess
import json

import requests
import simpleaudio as sa

from vad_record import record_vad
from faster_whisper import WhisperModel

# ---- TTS: Piper (yerli, oflayn) vÉ™ gTTS (fallback, onlayn) ----
from gtts import gTTS

PIPER_BIN   = os.environ.get("PIPER_BIN", str(Path.home() / "Desktop/piper/piper"))
PIPER_MODEL = str(Path.home() / "Desktop/piper_voices/en_US-ryan-medium.onnx")



OLLAMA_URL  = os.environ.get("OLLAMA_URL", "http://127.0.0.1:11434/v1/chat/completions")
OLLAMA_MODEL = os.environ.get("LLM_MODEL", "mistral:latest")  # sÉ™ndÉ™ quraÅŸdÄ±rÄ±lmÄ±ÅŸ model adÄ±


def speak_gtts(text: str, lang="en"):
    """Fallback TTS: gTTS + mpg123 (internet tÉ™lÉ™b edir)"""
    try:
        tmp_mp3 = "/tmp/tts.mp3"
        tts = gTTS(text=text, lang=lang)
        tts.save(tmp_mp3)
        os.system(f"mpg123 {tmp_mp3} > /dev/null 2>&1")
    except Exception as e:
        print("TTS(gTTS) error:", e)


def piper_tts(text: str):
    """Offline TTS using Piper"""
    if not Path(PIPER_BIN).exists():
        raise RuntimeError(f"Piper binary not found: {PIPER_BIN}")
    if not Path(PIPER_MODEL).exists():
        raise RuntimeError(f"Piper model not found: {PIPER_MODEL}")

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tf:
        outwav = tf.name

    # ---- Burada dÃ¼zgÃ¼n indentasiya ----
    cmd = [
        PIPER_BIN,
        "--model", PIPER_MODEL,
        "--output_file", outwav,
        "--length_scale", "1.30",      # yavaÅŸ danÄ±ÅŸÄ±q
        "--noise_scale", "0.33",       # artikulyasiya
        "--noise_w", "0.55",           # intonasiya
        "--sentence_silence", "0.20"   # cÃ¼mlÉ™lÉ™rarasÄ± pauza
    ]

    p = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    _, err = p.communicate(input=text.encode("utf-8"))
    if p.returncode != 0:
        raise RuntimeError(f"Piper failed: {err.decode(errors='ignore')}")

    wav = sa.WaveObject.from_wave_file(outwav)
    play = wav.play()
    play.wait_done()

    try:
        os.unlink(outwav)
    except Exception:
        pass



def ollama_chat(user_text: str) -> str:
    """Minimal chat-completions sorÄŸusu (Ollama)"""
    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {
                "role": "system",
                "content": (
                    "Respond briefly and naturally, like a human conversation partner. "
                    "Never mention that you are an AI or an assistant. "
                    "Keep answers short. Always reply in English unless asked otherwise."
                )
            },
            {"role": "user", "content": user_text}
        ],
        "stream": False
    }
    try:
        resp = requests.post(OLLAMA_URL, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print("âŒ LLM request failed:", e)
        return "Error: LLM request failed."


def record_and_transcribe():
    parser = argparse.ArgumentParser()
    parser.add_argument("--text", type=str, help="If provided, skip mic/VAD and chat with this text.")
    parser.add_argument("--no-tts", action="store_true", help="Disable TTS playback.")
    parser.add_argument("--tts", choices=["piper", "gtts", "off"], default="piper",
                        help="Choose TTS engine (default: piper)")
    args = parser.parse_args()

    # ---- TEXT CHAT MODE ----
    if args.text is not None:
        user_text = args.text.strip()
        if not user_text:
            print("Empty --text input.")
            return
        print(f"ğŸ“ Text input: {user_text}")
        reply = ollama_chat(user_text)
        print("\nğŸ¤– Reply:\n" + reply)
        if not args.no_tts and args.tts != "off":
            try:
                if args.tts == "piper":
                    piper_tts(reply)
                else:
                    speak_gtts(reply)
            except Exception as e:
                print("TTS error:", e)
        return

    # ---- MIC MODE (VAD â†’ Whisper CPU â†’ LLM â†’ TTS) ----
    out = Path.home() / "Desktop" / "output.wav"
    file_path = record_vad(output=str(out), silence_limit=1.2, device=None)
    if not file_path or not Path(file_path).exists():
        print("âŒ SÉ™s yazÄ±la bilmÉ™di.")
        return

    print(f"ğŸ§ YazÄ±lmÄ±ÅŸ fayl: {file_path}")
    print("ğŸ§  Whisper transkripsiya baÅŸlayÄ±r... (CPU)")

    # *** CPU MODE ***
    model = WhisperModel("base", device="cpu", compute_type="int8")  # CPU Ã¼Ã§Ã¼n tÉ™hlÃ¼kÉ™siz
    segments, info = model.transcribe(str(file_path), vad_filter=True, beam_size=1, best_of=1)
    print(f"ğŸŒ Dil: {info.language}")

    text = "".join(s.text for s in segments).strip()
    print("\nğŸ“ NÉ™ticÉ™:")
    print(text or "[boÅŸ]")

    if text:
        reply = ollama_chat(text)
        print("\nğŸ¤– Reply:\n" + reply)
        if not args.no_tts and args.tts != "off":
            try:
                if args.tts == "piper":
                    piper_tts(reply)
                else:
                    speak_gtts(reply)
            except Exception as e:
                print("TTS error:", e)


if __name__ == "__main__":
    record_and_transcribe()
