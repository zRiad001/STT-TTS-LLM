import sys
from faster_whisper import WhisperModel
from pathlib import Path

# ParametrlÉ™r: model Ã¶lÃ§Ã¼sÃ¼ vÉ™ hesablamanÄ±n tipi
MODEL_SIZE = "base"   # "tiny", "base", "small" (VM-dÉ™ "base int8" yaxÅŸÄ± balansdÄ±r)
COMPUTE    = "int8"   # "int8", "int8_float16", "int16", "float32"
DEVICE     = "cpu"    # VM-dÉ™ CPU

def transcribe_file(audio_path: str):
    audio = Path(audio_path)
    if not audio.exists():
        print(f"âŒ TapÄ±lmadÄ±: {audio}")
        sys.exit(1)

    print(f"ğŸ”Š Fayl: {audio}")
    print(f"ğŸ§  Model: {MODEL_SIZE}, device={DEVICE}, compute_type={COMPUTE}")

    model = WhisperModel(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE)

    segments, info = model.transcribe(
        str(audio),
        vad_filter=True,       # daxili VAD filtri kÃ¶mÉ™k edir
        beam_size=1,           # CPU-da sÃ¼rÉ™t Ã¼Ã§Ã¼n 1
        best_of=1,
        language=None          # None = avtomatik dil aÅŸkarlanmasÄ±
    )
    print(f"ğŸŒ Dil: {info.language} | no_speech_prob={getattr(info, 'no_speech_prob', None)}")

    text = "".join(s.text for s in segments).strip()
    print("\n=== NÉ™ticÉ™ ===")
    print(text)
    return text

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Ä°stifadÉ™: python transcribe_whisper.py <audio.wav/mp3/m4a>")
        sys.exit(1)
    transcribe_file(sys.argv[1])
